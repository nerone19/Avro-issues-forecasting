{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f76b10-9015-4a22-82f1-b5ae7d1abe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b0df1-9b4b-45a4-81a2-678e07f67a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = df.merge(df_transition,how=\"inner\",on=\"key\",suffixes=('', '_drop'))\n",
    "custom_df = merged_df\n",
    "for index, row in merged_df.iterrows():\n",
    "    \n",
    "    t_current = datetime.datetime.strptime(row['when'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    #day of week\n",
    "    custom_df.loc[index,'weekday']  = t_current.weekday()\n",
    "    custom_df.loc[index,'week_of_year'] = t_current.isocalendar()[1]\n",
    "    custom_df.loc[index,'day'] = t_current.day\n",
    "    custom_df.loc[index,'month'] = t_current.month\n",
    "    custom_df.loc[index,'year'] = t_current.year\n",
    "    #t_spent_in_month = t_spent_in_hours/30    \n",
    "    \n",
    "    if( str(row['resolutiondate']) != 'nan'):\n",
    "        t_created = datetime.datetime.strptime(row['created'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "        t_solved = datetime.datetime.strptime(row['resolutiondate'], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "        sol_time_spent = t_solved - t_current\n",
    "        time_passed_so_far = t_current - t_created\n",
    "\n",
    "        t_passed_seconds = time_passed_so_far.total_seconds()\n",
    "        t_spent_in_seconds = sol_time_spent.total_seconds()\n",
    "        t_spent_in_minutes = t_spent_in_seconds/60    \n",
    "        t_spent_in_hours = t_spent_in_minutes/60\n",
    "        t_spent_in_days = t_spent_in_hours/24\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if(t_spent_in_seconds > 0):\n",
    "            custom_df.loc[index,'sec_to_sol'] = t_spent_in_seconds\n",
    "        else:\n",
    "            #I noticed there are transitions in which the creation date is later than the solution date. I want to delete\n",
    "            #those because it is useless\n",
    "            custom_df.loc[index,'sec_to_sol'] = np.nan\n",
    "\n",
    "        if t_passed_seconds > 0:\n",
    "            custom_df.loc[index,'sec_passed_so_far'] = t_passed_seconds\n",
    "        else:\n",
    "            custom_df.loc[index,'sec_passed_so_far'] = 0\n",
    "custom_df.info()\n",
    "\n",
    "\n",
    "\n",
    "#for each key of the resolved issues, we keep count of the previous transictions made so far\n",
    "issue_keys = custom_df[\"key\"].unique()\n",
    "issue_keys_dict = { key : 0 for key in issue_keys }\n",
    "\n",
    "# #we sort rows by their time of creation\n",
    "sorted_df = custom_df.sort_values(by=['when'])\n",
    "for index, row in sorted_df.iterrows():\n",
    "    #we create new feature\n",
    "    custom_df.loc[index,'transictions_so_far'] = issue_keys_dict[row['key']]\n",
    "    #we keep count of the # of transictions so far\n",
    "    issue_keys_dict[row['key']] += 1\n",
    "    \n",
    "    \n",
    "custom_df.loc[custom_df['from_status'].isna(),['from_status']] = 'Inexistent'\n",
    "custom_df.loc[custom_df['days_since_open'].isna(),['days_since_open']] = 0\n",
    "custom_df.loc[custom_df['days_in_from_status'].isna(),['days_in_from_status']] = 0\n",
    "custom_df.loc[custom_df['description_length'].isna(),['description_length']] = custom_df['description_length'].mean()\n",
    "\n",
    "\n",
    "#feature to capture how many issues the assigned user solved so far \n",
    "problem_solvers = custom_df[custom_df['to_status'] == 'Resolved']['assignee'].value_counts().reset_index()\n",
    "problem_solvers= problem_solvers.rename(columns={\"index\": 'assignee', 'assignee': \"issue_solved_by_assignee\"})\n",
    "custom_df = pd.merge(custom_df, problem_solvers,  on=['assignee'])\n",
    "\n",
    "\n",
    "to_modify = ['Patch Available', 'Resolved','In Progress','Reopened']\n",
    "custom_df.loc[custom_df['from_status'].isin(to_modify),['from_status'] ] = 'RARE'\n",
    "\n",
    "\n",
    "to_modify = ['Resolved','In Progress','Reopened']\n",
    "custom_df.loc[custom_df['to_status'].isin(to_modify),['to_status'] ] = 'RARE'\n",
    "df_day_count.loc[df_day_count['status'].isin(to_modify),['status'] ] = 'RARE'\n",
    "\n",
    "\n",
    "def get_calender_day(x):\n",
    "    o = datetime.datetime.strptime(x,\"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "    \n",
    "    return str(o.day) + \"-\" + str(o.month) + \"-\" + str(o.year)\n",
    "    \n",
    "#I convert both the Iso date into string of the following format (dd-mm-yyyy) in order to \n",
    "custom_df['calendar_day'] = custom_df['when'].apply(\n",
    "        lambda x: get_calender_day(x) )  \n",
    "\n",
    "df_day_count['calendar_day'] = df_day_count['day'].apply(\n",
    "        lambda x: get_calender_day(x) )  \n",
    "\n",
    "\n",
    "#we merge the previous custom df made so far  and the day_count df\n",
    "custom_df = pd.merge(custom_df, df_day_count,  how='left', left_on=['calendar_day','to_status'], right_on = ['calendar_day','status'],suffixes=('', '_drop'))\n",
    "#we drop every duplicate from the merge process\n",
    "custom_df.drop([col for col in custom_df.columns if 'drop' in col], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# number of issue of the same per month and year\n",
    "custom_df['count_month_of_year'] = custom_df.groupby(['year','month'])['count'].transform('sum')\n",
    "custom_df['count_year'] =  custom_df.groupby(['year'])['count'].transform('sum')\n",
    "\n",
    "\n",
    "group_assignee = custom_df.groupby(['key'])['assignee'].unique().reset_index()\n",
    "group_reporter = custom_df.groupby(['key'])['reporter'].unique().reset_index()\n",
    "group_who = custom_df.groupby(['key'])['who'].unique().reset_index()\n",
    "\n",
    "\n",
    "merge_groups = pd.merge(group_assignee, group_reporter,  on='key')\n",
    "merge_groups = pd.merge(merge_groups, group_who,  on='key')\n",
    "\n",
    "for index, row in merge_groups.iterrows():\n",
    "    teamList = list(row['assignee'])\n",
    "    \n",
    "    for el in row['reporter']:\n",
    "        if(el not in teamList):\n",
    "            teamList.append(el)\n",
    "            \n",
    "    for el in row['who']:\n",
    "        if(el not in teamList):\n",
    "            teamList.append(el)\n",
    "            \n",
    "    merge_groups.loc[index,'team_count'] = len(teamList)\n",
    "    \n",
    "    \n",
    "custom_df = pd.merge(custom_df, merge_groups,  on='key' ,suffixes=('', '_drop'))\n",
    "custom_df.drop([col for col in custom_df.columns if 'drop' in col], axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
